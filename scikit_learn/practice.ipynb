{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Exercise (Practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### End-to-end Scikit-Learn classification workflow\n",
    "1. Get dataset ready\n",
    "2. Prepare a machine learning model to make predictions\n",
    "3. Fit the model to the data and make a prediction\n",
    "4. Evaluate the model's predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Getting a dataset ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import heart_disease dataset and save it to a variable\n",
    "heart_disease = pd.read_csv('data/heart-disease.csv')\n",
    "\n",
    "# View first 5 rows\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build a machine learning model on all columns except `target` to predict `target`.\n",
    "* **target variable** (also called y or labels) = `target` column\n",
    "* **independent variables** = all other columns\n",
    "\n",
    "Since our target is going to be heart disease or not, we know this is a **classification** problem.\n",
    "* **Classification** --> if target variable is one thing or another (heart disease or not)\n",
    "* **Regression** --> if target column is a numeric value (Price)\n",
    "\n",
    "Knowing this, let's create `x` and `y` by splitting up our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X (all columns except target)\n",
    "X = heart_disease.drop('target', axis=1) # (label name, corresponding axis)\n",
    "\n",
    "# Create y (only the target column)\n",
    "y = heart_disease['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Scikit-Learn to split into training and test setss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn's model_selection module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setup a NumPy random seed equal to 42\n",
    "np.random.seed(42)\n",
    "\n",
    "# Use train_test_split to split X & y into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) # default test size is 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227, 13), (76, 13), (227,), (76,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the different shapes of the training and test datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: The default `test_size` in `train_test_split()` is 0.25; meaning, the test dataset is 25% of the total, while the training dataset is 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can build a machine learning model to fit patternd in the training data and then make predictions on the test data.\n",
    "\n",
    "To figure out which machine learning model to use, you can refer to [Scikit-Learn's machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
    "\n",
    "Let's say you decide to use the [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preparing a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier from sklearn's ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate an instance of RandomForestClassifier as clf\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a `RandomForestClassifier` instance, we can fit the training data and make predictions on our test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is an instance?\n",
    "\n",
    "An instance, in object-oriented programming (OOP), is a specific realization of any object. An object may be varied in a number of ways. Each realized variation of that object is an instance. The creation of a realized instance is called instantiation.\n",
    "\n",
    "Each time a program runs, it is an instance of that program. In languages that create objects from classes, an object is an instantiation of a class. That is, it is a member of a given class that has specified values rather than variables. In a non-programming context, you could think of \"dog\" as a class and your particular dog as an instance of that class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fitting a model and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the RandomForestClassifier to the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted model to make predictions on the test data\n",
    "# save the predictions to a variable called y_preds\n",
    "y_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Evaluating a models predictions\n",
    "\n",
    "We can check our model by calling the `score()` method and passing it the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the fitted model on the training set using the score() function.\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289473684210527"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the fitted model on the test set using the score() function.\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Experimenting with different classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a series of different machine learning models and see which gets the best results on our dataset.\n",
    "\n",
    "Classification models from [Scikit-Learns machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html):\n",
    "* [LinearSVC](https://scikit-learn.org/stable/modules/svm.html#classification)\n",
    "* [KNeighborsClassifier](https://scikit-learn.org/stable/modules/neighbors.html)(also known as K-Nearest Neighbors or KNN)\n",
    "* [SVC](https://scikit-learn.org/stable/modules/svm.html#classification) (also known as support vector classifier, a form of [support vector machine](https://en.wikipedia.org/wiki/Support-vector_machine))\n",
    "* [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) (despite the name, this is actually a classifier)\n",
    "* [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) (an ensemble method and what we used above)\n",
    "\n",
    "We will use the same workflow as above, except for multiple models:\n",
    "1. Import a machine learning model\n",
    "2. Get it ready\n",
    "3. Fit it to the data and make predictions\n",
    "4. Evaluate the fitted model\n",
    "\n",
    "Note: Since we've already got the data, we can reuse it in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearSVC from sklearns svm module\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Import KNeighborsClassifier from sklearn's neighbors module\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import SVC from sklearn's svm module\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Import LogisticRegression from sklearn's linear_model module\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Note: we don't have to import RandomForestClassifier, since we already have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the consistency of Scikit-Learn's API design, we can use virtually the same code to fit, score and make predictions with each or our models.\n",
    "\n",
    "To see which model performs best, we'll do the following:\n",
    "1. Instantiate each model in a dictionary\n",
    "2. Create an empty results dictionary\n",
    "3. Fit each model on the training data\n",
    "4. Score each model on the test data\n",
    "5. Check the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Instantiate each model in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary called models which containd all of the classification models\n",
    "models = {'LinearSVC': LinearSVC(),\n",
    "          'KNN': KNeighborsClassifier(),\n",
    "          'SVC': SVC(),\n",
    "          'LogisticRegression': LogisticRegression(),\n",
    "          'RandomForestClassifier': RandomForestClassifier()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create an empty results dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each model we're using has the same `fit()` and `score()` functions we can loop through our models dictionary and call `fit()` on training data and then `score()` on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3./4./5. Fit, score and check results of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashleycasanova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/ashleycasanova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LinearSVC': 0.8552631578947368,\n",
       " 'KNN': 0.6973684210526315,\n",
       " 'SVC': 0.6973684210526315,\n",
       " 'LogisticRegression': 0.881578947368421,\n",
       " 'RandomForestClassifier': 0.8552631578947368}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop through the models dictionary items, fitting the model on the training data\n",
    "# and appending the model name and model score on the test data to the results dictionary\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    results[model_name] = model.score(X_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which model performed the best?\n",
    "\n",
    "LinearSVC performed best.\n",
    "```\n",
    "{'LinearSVC': 0.8421052631578947,\n",
    " 'KNeighborsClassifier': 0.618421052631579,\n",
    " 'SVC': 0.6447368421052632,\n",
    " 'LogisticRegression': 0.8157894736842105,\n",
    " 'RandomForestClassifier': 0.8289473684210527}\n",
    "```\n",
    "* Do the results change each time you run the cell?\n",
    "\n",
    "Yes, the second time running the cell RandomForestClassifier performed best.\n",
    "```\n",
    "{'LinearSVC': 0.7763157894736842,\n",
    " 'KNeighborsClassifier': 0.618421052631579,\n",
    " 'SVC': 0.6447368421052632,\n",
    " 'LogisticRegression': 0.8157894736842105,\n",
    " 'RandomForestClassifier': 0.8289473684210527}\n",
    "```\n",
    "\n",
    "* Why do you think this is?\n",
    "\n",
    "Due to the randomness of how each model finds patterns in the data, you might notice different results each time\n",
    "\n",
    "Without manually setting the random state using the `random state` parameter of some models or using a Numpy random seed, every time you run the cell, you'll ger slightly different results.\n",
    "\n",
    "Let's see this in effect by running the same code, but setting the NumPy random seed equal to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashleycasanova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/ashleycasanova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LinearSVC': 0.5789473684210527,\n",
       " 'KNN': 0.6973684210526315,\n",
       " 'SVC': 0.6973684210526315,\n",
       " 'LogisticRegression': 0.881578947368421,\n",
       " 'RandomForestClassifier': 0.8157894736842105}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    results[model_name] = model.score(X_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the cell above a few times, what do you notice about the results?\n",
    "\n",
    "The results no longer change.\n",
    "```\n",
    "{'LinearSVC': 0.4473684210526316,\n",
    " 'KNeighborsClassifier': 0.618421052631579,\n",
    " 'SVC': 0.6447368421052632,\n",
    " 'LogisticRegression': 0.8157894736842105,\n",
    " 'RandomForestClassifier': 0.8026315789473685}\n",
    "```\n",
    "\n",
    "* Which model performes the best this time?\n",
    "\n",
    "The LogisticRegression model runs the best.\n",
    "\n",
    "* What happens if you add a NumPy random seed to the cell where you called 'train_test_split()` (towards the top of the notebook)?\n",
    "\n",
    "Nothing, after setting NumPy's random seed equal to 42, I ran all of the following cells.  Rerunning the for loop without the random seed in the same cell, generated different results every time.\n",
    "\n",
    "Let's make our results a little more visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pandas dataframe with the data as the values of the results dictionary,\n",
    "# the index as the keys of the results dictionary and a single column called accuracy.\n",
    "# Be sure to save the dataframe to a variable.\n",
    "results_df = pd.DataFrame(results.values(), # data\n",
    "                          results.keys(), # index\n",
    "                          columns=['Accuracy'])\n",
    "\n",
    "# Create a bar plot of the results dataframe using plot.bar()\n",
    "results_df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LogisticRegression` performed best when using `np.random.seed(42)`.\n",
    "\n",
    "Let's tune its hyperparameters and see if we can improve it.\n",
    "\n",
    "#### Hyperparameter Tuning\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c2753ee3d3b747e2bc727f5ec1bf0708a31b4b3dd6e00944156fdd88e394a6e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
